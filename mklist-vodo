#!/usr/bin/env python

"""
Extract list of free movies available from vodo.net.
"""

import json
import lxml.html
import urllib2
import urlparse

def get(url):
    opener = urllib2.build_opener()
    opener.addheaders = [('User-Agent', 'curl/7.52.1')]
    f = opener.open(url)
    return f.read()

def parsepage(l, url):
    try:
        html = get(url)
        root = lxml.html.fromstring(html)
        imdburl = url
        for a in root.cssselect("a"):
            if -1 != a.attrib['href'].find("imdb.com"):
                imdburl = urlparse.urljoin(url, a.attrib['href'])
                if '/' != imdburl[-1]:
                    imdburl = imdburl + '/'
        if imdburl == url:
            print "warning: missing imdb link for %s" % url
        title = root.cssselect('meta[property="og:title"]')[0].get('content')
        year = root.cssselect('div.title-holder span.alt')[0].text_content().strip('()')
        l[imdburl] = {
            'status' : 'free',
            'freenessurl' : url,
            'title' : title,
            }
        if '' != year:
            l[imdburl]['year'] = int(year)

        print l[imdburl]
    except urllib2.HTTPError as e:
        pass
    return None

def savelist(l, name = None):
    if not name:
        name = 'free-movies-vodo.json'
    with open(name, 'wt') as out:
        json.dump(l,
                  out,
                  sort_keys=True,
                  indent=4,
                  separators=(',', ': '))

url = "http://vodo.net/films/"
html = get(url)
root = lxml.html.fromstring(html)
entries = {}
for a in root.cssselect("div.sticker a"):
    entryurl = urlparse.urljoin(url, a.attrib['href'])
    parsepage(entries, entryurl)
savelist(entries)
