#!/usr/bin/env python

"""
Search for movies in the Internet Archive similar to how the Butter
plugin do it, and output the list with IMDB title IDs similar to the
other list of free movies.  Look for IMDB title references in the
description and other relevant tags.

If the search result do not return a IMDB ID, see if the wikidata set
or the manually created data set have such ID and use this one.
"""

import json
import urllib
import urllib2
import re
import time

def fetch(page=1):
    print("Fetching page %d" % page)
    """
Based on the search URL found in
https://github.com/butterproviders/butter-provider-archive
The search result is less than 1000 entries 2017-11-05.

Removing the 'year' requirement result in several thousand entries more.
"""
    # Search term:
    term = """
collection:moviesandfilms
AND NOT collection:movie_trailers
AND NOT collection:sabucat_trailers
AND NOT collection:stock_footage
AND NOT collection:home_movies
AND NOT collection:prelinger_mashups
AND -mediatype:collection
AND format:"Archive BitTorrent"
"""
    # Limiting to entries with year was part of the original Butter
    # search, but reduses around 17000 entries to around 500.
    if False:
        term = term + " AND year"
        
    url = 'https://archive.org/advancedsearch.php?sort%%5B%%5D=&sort%%5B%%5D=&sort%%5B%%5D=&output=json&rows=100000&page=%d' % page
    url = url + '&q=' + urllib.quote_plus(term)
    h = { "Accept" : "application/json"}
    try:
        request = urllib2.Request(url, headers=h)
        jsondata = urllib2.urlopen(request).read()
        #print jsondata
        data = json.loads(jsondata)
        return data
    except urllib2.HTTPError as e:
        print("Error:", str(e))
        return None

def locate_imdb_refs(text):
    if type (text) is list:
        text = " ".join(text)
    if -1 != text.find('imdb.com/title/tt'):
        p = re.compile('(https?://[w.]*imdb.com/title/tt[^/ "]+/?)')
        imdbs = p.findall(text)
        newimdbs = []
        for i in imdbs:
            i = i.replace('/imdb.com/', '/www.imdb.com/')
            if '/' != i[-1]:
                i = i + '/'
            newimdbs.append(i)
        imdbs = newimdbs
        return imdbs
    return []

def loadlist(l, path):
    try:
        with open(path, 'rt') as input:
            n = json.load(input)
            for id in n.keys():
                if not id in l:
                    l[id] = n[id]
                else:
                    if n[id]['freenessurl'] != l[id]['freenessurl']:
                        l[id]['archive'] = n[id]['freenessurl']
    except IOError as e:
        return {}

def savelist(l, name = None):
    if not name:
        name = 'free-movies-archive-org-butter.json'
    with open(name, 'wt') as out:
        json.dump(l,
                  out,
                  sort_keys=True,
                  indent=4,
                  separators=(',', ': '))
def main():
    wplist = {}
    loadlist(wplist, 'free-movies-archive-org-wikidata.json')
    loadlist(wplist, 'free-movies-manual.json')
    print "C", len(wplist.keys())

    outlist = {}
    page = 1
    while True:
        l = fetch(page)
        if not l or 0 == len(l['response']['docs']):
            break
        for e in l['response']['docs']:
            freenessurl = "https://archive.org/details/%s" % e['identifier']
            imdbmap = {}
            if 'description' in e:
                for i in locate_imdb_refs(e['description']):
                    imdbmap[i] = True
            if 'stripped_tags' in e:
                for i in locate_imdb_refs(e['stripped_tags']):
                    imdbmap[i] = True
            fle = {
                'status' : 'free',
                'freenessurl' : freenessurl,
                'title' : e['title'],
                }
            if 'year' in e:
                fle['year'] = e['year']
            if 0 == len(imdbmap.keys()):
                for wpimdb in wplist.keys():
                    for field in ['freenessurl', 'archive']:
                        if field in wplist[wpimdb] \
                           and wplist[wpimdb][field] == freenessurl:
                            imdbmap[wpimdb] = True
            if 0 == len(imdbmap.keys()):
                imdbmap[freenessurl] = True
            for i in imdbmap.keys():
                if i not in outlist:
                    outlist[i] = fle
                else:
                    if 'year' in fle and 'year' not in outlist[i]:
                        outlist[i]['year'] = fle['year']
                    if 'archive' not in outlist[i]:
                        outlist[i]['archive'] = fle['freenessurl']
                    elif 'archive2' not in outlist[i]:
                        outlist[i]['archive2'] = fle['freenessurl']
                    elif 'archive3' not in outlist[i]:
                        outlist[i]['archive3'] = fle['freenessurl']
                    elif 'archive4' not in outlist[i]:
                        outlist[i]['archive4'] = fle['freenessurl']
                    elif 'archive5' not in outlist[i]:
                        outlist[i]['archive5'] = fle['freenessurl']
                    elif 'archive6' not in outlist[i]:
                        outlist[i]['archive6'] = fle['freenessurl']
                    elif 'archive7' not in outlist[i]:
                        outlist[i]['archive7'] = fle['freenessurl']
                    elif 'archive8' not in outlist[i]:
                        outlist[i]['archive8'] = fle['freenessurl']
                    else:
                        outlist[i]['archive9'] = fle['freenessurl']
        page = page + 1
        time.sleep(3)
    savelist(outlist)

    print("Wrote %d" % len(outlist.keys()))

if __name__ == '__main__':
    main()
