#!/usr/bin/env python

"""
Search for movies in the Internet Archive, and output the list with
IMDB title IDs similar to the other list of free movies.  Look for
IMDB title references in the description and other relevant tags.

It is based on  how the Butter plugin search for movies, but extended
to get more hits.

If the search result do not return a IMDB ID, see if the wikidata set
or the manually created data set have such ID and use this one.
"""

import json
import urllib
import urllib2
import re
import time

def fetch(page=1):
    print("Fetching page %d" % page)
    """
Based on the search URL found in
https://github.com/butterproviders/butter-provider-archive
The search result is less than 1000 entries 2017-11-05.

Removing the 'year' requirement result in several thousand entries more.
"""
    # Search term:
    term = """
(collection:moviesandfilms
OR collection:animationandcartoons
OR collection:classic_cartoons)
AND NOT collection:movie_trailers
AND NOT collection:sabucat_trailers
AND NOT collection:stock_footage
AND NOT collection:home_movies
AND NOT collection:prelinger_mashups
AND -mediatype:collection
AND format:"Archive BitTorrent"
"""
    # Limiting to entries with year was part of the original Butter
    # search, but reduses around 17000 entries to around 500.
    if False:
        term = term + " AND year"
        
    url = 'https://archive.org/advancedsearch.php?sort%%5B%%5D=&sort%%5B%%5D=&sort%%5B%%5D=&output=json&rows=100000&page=%d' % page
    url = url + '&q=' + urllib.quote_plus(term)
    h = { "Accept" : "application/json"}
    try:
        request = urllib2.Request(url, headers=h)
        jsondata = urllib2.urlopen(request).read()
        #print jsondata
        data = json.loads(jsondata)
        return data
    except urllib2.HTTPError as e:
        print("Error:", str(e))
        return None

def locate_imdb_refs(text):
    if type (text) is list:
        text = " ".join(text)
    if -1 != text.find('imdb.com/title/tt'):
        p = re.compile('(https?://[w.]*imdb.com/title/tt[^/ "]+/?)')
        imdbs = p.findall(text)
        newimdbs = []
        for i in imdbs:
            i = i.replace('/imdb.com/', '/www.imdb.com/')
            if '/' != i[-1]:
                i = i + '/'
            newimdbs.append(i)
        imdbs = newimdbs
        return imdbs
    return []

def loadlist(l, path):
    try:
        with open(path, 'rt') as input:
            n = json.load(input)
            for id in n.keys():
                freenessurl = []
                for field in ['freenessurl', 'archive', 'archive1', 'archive2',
                              'archive3', 'archive4', 'archive5', 'archive6']:
                    if field in n[id] and n[id][field] not in freenessurl:
                        freenessurl.append(n[id][field])
                        del n[id][field]
                n[id]['freenessurl'] = freenessurl
                if not id in l:
                    l[id] = n[id]
                else:
                    for url in n[id]['freenessurl']:
                        if url not in l[id]['freenessurl']:
                            l[id]['freenessurl'].append(url)
    except IOError as e:
        return {}

def savelist(l, name = None):
    if not name:
        name = 'free-movies-archive-org-search.json'
    with open(name, 'wt') as out:
        json.dump(l,
                  out,
                  sort_keys=True,
                  indent=4,
                  separators=(',', ': '))
def main():
    wplist = {}
    loadlist(wplist, 'free-movies-archive-org-wikidata.json')
    loadlist(wplist, 'free-movies-manual.json')
    print "C", len(wplist.keys())

    outlist = {}
    page = 1
    while True:
        l = fetch(page)
        if not l or 0 == len(l['response']['docs']):
            break
        for e in l['response']['docs']:
            freenessurl = "https://archive.org/details/%s" % e['identifier']
            imdbmap = {}
            if 'description' in e:
                for i in locate_imdb_refs(e['description']):
                    imdbmap[i] = True
            if 'stripped_tags' in e:
                for i in locate_imdb_refs(e['stripped_tags']):
                    imdbmap[i] = True
                    # Pick the first title if the result is a list
                    if list == type(e['title']):
                        e['title'] = sorted(e['title'])[0]
            fle = {
                'status' : 'free',
                'freenessurl' : [freenessurl],
                'title' : e['title'],
                }
            if 'year' in e:
                fle['year'] = e['year']
            # Check if the archive.org ID already have a known IMDB title ID
            if 0 == len(imdbmap.keys()):
                for wpimdb in wplist.keys():
                    if 'freenessurl' in wplist[wpimdb] \
                       and freenessurl in wplist[wpimdb]['freenessurl']:
                        imdbmap[wpimdb] = True
            # If not, use archive.org ID as unique ID
            if 0 == len(imdbmap.keys()):
                imdbmap[freenessurl] = True
            for i in imdbmap.keys():
                if i not in outlist:
                    outlist[i] = fle
                else:
                    if 'year' in fle and 'year' not in outlist[i]:
                        outlist[i]['year'] = fle['year']
                    if freenessurl not in outlist[i]['freenessurl']:
                        outlist[i]['freenessurl'].append(freenessurl)
        page = page + 1
        time.sleep(3)
    # Rewrite freenessurl array to individual fields (freenessurl,
    # archive, archive1...) in predictable/sorted order
    for i in outlist:
        if 1 == len(outlist[i]['freenessurl']):
            outlist[i]['freenessurl'] = outlist[i]['freenessurl'][0]
        else:
            sl = sorted(outlist[i]['freenessurl'])
            outlist[i]['freenessurl'] = sl[0]
            seq = 0
            for u in sl[1:]:
                if 0 == seq:
                    field = 'archive'
                else:
                    field = "archive%d" % seq
                outlist[i][field] = u
                seq = seq + 1
                
    savelist(outlist)

    print("Wrote %d" % len(outlist.keys()))

if __name__ == '__main__':
    main()
